___
# FullstackDL
[Full Stack Deep Learning - Spring 2021](https://fullstackdeeplearning.com/spring2021/) 강의로 스터디 진행
- 모든 방식은 멤버들과의 합의에 따라 바뀔 수 있음
- 매주 금요일 [Gooogle Meet](https://meet.google.com/fyc-fkqu-jzw) 로 스터디 진행 
- 매 회주 스터디가 끝난 후 회고를 진행하고, 진행했던 내용을 [Log](https://docs.google.com/spreadsheets/d/1kBVQBXKipvha-6S6SwpSN0dJe0bxl-hXQR3rPDjLQBU/edit?usp=sharing) 로 남김 (멤버공개)

___
# Member
- [허원재](https://github.com/rukka0808)
- [엄다연](https://github.com/dayeoni-1376)
- [조준우](https://github.com/fifane)
- [여상엽](https://github.com/Sang-Yeop-Yeo)

___
# Schedule

|day|Topic|Role|Tag|
|---|---|---|---|
|21.05.21|1.Fundamental|* Presenter : 엄다연 <br>* Lecture1 : 조준우 <br>* Lab1 : 허원재 <br>* git-manager: 여상엽 |# Neural Networks # Universality <br> # Learning Problems # Loss Function <br> # Backpropagation # CUDA # Setup <br> # Train MLP model MNIST <br> # Tensorflow # Pytorch | 
|21.05.30|2.CNNs|* Presenter : 허원재 <br>* Lecture2A : 조준우 <br>* Lecture2B : 여상엽 <br>* Lab : 엄다연 | # Conv # Stride # Padding # Receptive Field <br> # 1x1 Conv # AlexNet # ZFNet <br> # VGGNet # GoogLeNet # RestNet <br> # Localization  # Detection # Overfit # Adversarial Attacks <br> # Train CNN Model EMNIST # synthetic EMNIST lines |
|21.06.20|3.RNNs|* Presenter : 조준우 <br>* Lecture3 : 여상엽 <br>* Lab3 : 엄다연 <br>* git-manager: 허원재| # sequence problem # disadvantage of Feedforward networks # gradient vanishing # LSTMs <br> # forget gate #input gate  # problems of LSTMs <br> # resNet #attention #bidirectionality <br> #CTC loss #convNet 
|21.06.27|4.Transformers|* Presenter : 여상엽 <br>* Lecture4 : 엄다연 <br>* Lab4 : 허원재 <br>* git-manager: 조준우 | # sequence problem # disadvantage of Feedforward networks # gradient vanishing # Receptive Field <br> # 1x1 Conv # AlexNet # ZFNet <br> # VGGNet # GoogLeNet # RestNet <br> # Localization  # Detection # Overfit # Adversarial Attacks <br> # Train CNN Model EMNIST # synthetic EMNIST lines |
